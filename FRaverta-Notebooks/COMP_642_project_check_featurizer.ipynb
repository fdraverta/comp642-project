{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Ju93ofzAAM",
        "outputId": "e1ea7757-7c47-48de-c4cf-7d7aced47160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m2024-04-22 21:49:55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDownloading ZIP file with the data set...\u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mOpening ZIP file...           \u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mReading CSV file...           \u001b[0m \u001b[36mfname\u001b[0m=\u001b[35mtrain.csv\u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData set loaded successfully. \u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBaseline model computed.      \u001b[0m \u001b[36mtest_mae\u001b[0m=\u001b[35m5.8499749700259205\u001b[0m \u001b[36mtrain_mae\u001b[0m=\u001b[35m6.481303604250604\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# To find local version of the library\n",
        "sys.path.append(os.path.join(\"./comp642-project/FRaverta-Notebooks\"))\n",
        "\n",
        "# here is your import\n",
        "from featurizer import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5t35nkHjQIu",
        "outputId": "da6b8420-f9d8-4bef-ffe3-4eba8fb8bf91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m2024-04-22 21:50:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDownloading ZIP file with the data set...\u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mOpening ZIP file...           \u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mReading CSV file...           \u001b[0m \u001b[36mfname\u001b[0m=\u001b[35mtrain.csv\u001b[0m\n",
            "\u001b[2m2024-04-22 21:50:52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData set loaded successfully. \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "data = TradingAtTheCloseDS()\n",
        "train_data, test_data = data.get_train_test_data()\n",
        "#train_mae, test_mae = data.compute_baseline_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fssyGMxz1VDr"
      },
      "outputs": [],
      "source": [
        "#drop rows with nan in wap column\n",
        "train_data = train_data.dropna(subset=['wap'])\n",
        "test_data = test_data.dropna(subset=['wap'])\n",
        "\n",
        "x_train, y_train = train_data[data.categorical_features + data.numerical_features], train_data[data.y_column]\n",
        "x_test, y_test = test_data[data.categorical_features + data.numerical_features], test_data[data.y_column]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdZPMyZcqXX"
      },
      "source": [
        "# Random Forest on DATASET with all features, features nan set to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_2zKhRh31I",
        "outputId": "b2ee36ec-6f57-406a-e423-232b127e86a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4621815 entries, 0 to 4621979\n",
            "Data columns (total 14 columns):\n",
            " #   Column                   Dtype  \n",
            "---  ------                   -----  \n",
            " 0   stock_id                 int64  \n",
            " 1   imbalance_buy_sell_flag  int64  \n",
            " 2   seconds_in_bucket        int64  \n",
            " 3   imbalance_size           float64\n",
            " 4   reference_price          float64\n",
            " 5   matched_size             float64\n",
            " 6   far_price                float64\n",
            " 7   near_price               float64\n",
            " 8   bid_price                float64\n",
            " 9   bid_size                 float64\n",
            " 10  ask_price                float64\n",
            " 11  ask_size                 float64\n",
            " 12  wap                      float64\n",
            " 13  target                   float64\n",
            "dtypes: float64(11), int64(3)\n",
            "memory usage: 528.9 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "stock_id                         0\n",
              "imbalance_buy_sell_flag          0\n",
              "seconds_in_bucket                0\n",
              "imbalance_size                   0\n",
              "reference_price                  0\n",
              "matched_size                     0\n",
              "far_price                  2553470\n",
              "near_price                 2520990\n",
              "bid_price                        0\n",
              "bid_size                         0\n",
              "ask_price                        0\n",
              "ask_size                         0\n",
              "wap                              0\n",
              "target                           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.info()\n",
        "\n",
        "# get information about nan values in each column\n",
        "x_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXp4NTNmjaXq",
        "outputId": "f6d44855-512f-4c8d-a22f-b5c6c5877b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 615945 entries, 4621980 to 5237979\n",
            "Data columns (total 14 columns):\n",
            " #   Column                   Non-Null Count   Dtype  \n",
            "---  ------                   --------------   -----  \n",
            " 0   stock_id                 615945 non-null  int64  \n",
            " 1   imbalance_buy_sell_flag  615945 non-null  int64  \n",
            " 2   seconds_in_bucket        615945 non-null  int64  \n",
            " 3   imbalance_size           615945 non-null  float64\n",
            " 4   reference_price          615945 non-null  float64\n",
            " 5   matched_size             615945 non-null  float64\n",
            " 6   far_price                275293 non-null  float64\n",
            " 7   near_price               279975 non-null  float64\n",
            " 8   bid_price                615945 non-null  float64\n",
            " 9   bid_size                 615945 non-null  float64\n",
            " 10  ask_price                615945 non-null  float64\n",
            " 11  ask_size                 615945 non-null  float64\n",
            " 12  wap                      615945 non-null  float64\n",
            " 13  target                   615945 non-null  float64\n",
            "dtypes: float64(11), int64(3)\n",
            "memory usage: 70.5 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "stock_id                        0\n",
              "imbalance_buy_sell_flag         0\n",
              "seconds_in_bucket               0\n",
              "imbalance_size                  0\n",
              "reference_price                 0\n",
              "matched_size                    0\n",
              "far_price                  340652\n",
              "near_price                 335970\n",
              "bid_price                       0\n",
              "bid_size                        0\n",
              "ask_price                       0\n",
              "ask_size                        0\n",
              "wap                             0\n",
              "target                          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.info()\n",
        "\n",
        "# get information about nan values in each column\n",
        "x_test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-E__hDMeiPcy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2628258/1991184684.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_train.loc[:,'far_price'] = x_train['far_price'].fillna(0)\n",
            "/tmp/ipykernel_2628258/1991184684.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_train.loc[:,'near_price'] = x_train['near_price'].fillna(0)\n",
            "/tmp/ipykernel_2628258/1991184684.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_test.loc[:,'far_price'] = x_test['far_price'].fillna(0)\n",
            "/tmp/ipykernel_2628258/1991184684.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_test.loc[:,'near_price'] = x_test['near_price'].fillna(0)\n"
          ]
        }
      ],
      "source": [
        "x_train.loc[:,'far_price'] = x_train['far_price'].fillna(0)\n",
        "x_train.loc[:,'near_price'] = x_train['near_price'].fillna(0)\n",
        "\n",
        "x_test.loc[:,'far_price'] = x_test['far_price'].fillna(0)\n",
        "x_test.loc[:,'near_price'] = x_test['near_price'].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPUcpWj3cjSJ",
        "outputId": "c8c67d40-9baf-487a-e47d-1199ff4243a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:  7.9min remaining:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed: 12.0min finished\n",
            "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest MAE: 0.003943358133017773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done   8 out of  11 | elapsed:    0.2s remaining:    0.1s\n",
            "[Parallel(n_jobs=8)]: Done  11 out of  11 | elapsed:    0.2s finished\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Create a \"do-nothing\" transformer\n",
        "no_op_transformer = FunctionTransformer(lambda x: x)\n",
        "\n",
        "\n",
        "\n",
        "# Numerical pipeline with feature addition\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('do_nothing', no_op_transformer)\n",
        "])\n",
        "\n",
        "# Categorical pipeline\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('onehot', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# Combine pipelines\n",
        "preprocessing_pipeline = ColumnTransformer([\n",
        "    ('num', numerical_pipeline, data.numerical_features),\n",
        "    ('cat', categorical_pipeline, data.categorical_features)\n",
        "])\n",
        "\n",
        "# Applying the pipeline\n",
        "x_train_transformed = preprocessing_pipeline.fit_transform(x_train)\n",
        "x_test_transformed = preprocessing_pipeline.transform(x_test)\n",
        "\n",
        "\n",
        "random_forest = RandomForestRegressor(n_estimators=11, random_state=42, verbose=1, n_jobs=-1,  max_depth=10)\n",
        "random_forest.fit(x_train_transformed, y_train.values.reshape(-1))\n",
        "y_pred = random_forest.predict(x_test_transformed)\n",
        "\n",
        "print(f\"Random Forest MAE: {mean_absolute_error(y_test, y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8UeXKVXcyYW"
      },
      "source": [
        "# 2 Random forest models, one first 5 minutes other second 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "j36lQBYFdAWo"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Index dimension must be 1 or 2",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m random_forest_second_5min \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,  max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# select those rows which 'far_price' is not nan\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m x_train_transformed_first_5min \u001b[38;5;241m=\u001b[39m x_train_transformed[\u001b[43mx_train_transformed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfar_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()]\n\u001b[1;32m      6\u001b[0m x_train_transformed_second_5min \u001b[38;5;241m=\u001b[39m x_train_transformed[x_train_transformed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfar_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n\u001b[1;32m      8\u001b[0m y_train_first_5min  \u001b[38;5;241m=\u001b[39m y_train[x_train_transformed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfar_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\n",
            "File \u001b[0;32m~/development/ML/venv/lib/python3.8/site-packages/scipy/sparse/_index.py:47\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 47\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
            "File \u001b[0;32m~/development/ML/venv/lib/python3.8/site-packages/scipy/sparse/_index.py:159\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    157\u001b[0m         row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m M\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_asindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isintlike(col):\n\u001b[1;32m    162\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(col)\n",
            "File \u001b[0;32m~/development/ML/venv/lib/python3.8/site-packages/scipy/sparse/_index.py:183\u001b[0m, in \u001b[0;36mIndexMixin._asindices\u001b[0;34m(self, idx, length)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid index\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex dimension must be 1 or 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[0;31mIndexError\u001b[0m: Index dimension must be 1 or 2"
          ]
        }
      ],
      "source": [
        "random_forest_first_5min = RandomForestRegressor(n_estimators=10, random_state=42, verbose=1, n_jobs=-1,  max_depth=10)\n",
        "random_forest_second_5min = RandomForestRegressor(n_estimators=10, random_state=42, verbose=1, n_jobs=-1,  max_depth=10)\n",
        "\n",
        "# select those rows which 'far_price' is not nan\n",
        "x_train_transformed_first_5min = x_train_transformed[x_train_transformed['far_price'].notna()]\n",
        "x_train_transformed_second_5min = x_train_transformed[x_train_transformed['far_price'].isna()]\n",
        "\n",
        "y_train_first_5min  = y_train[x_train_transformed['far_price'].notna()]\n",
        "y_train_second_5min = y_train[x_train_transformed['far_price'].isna()]\n",
        "\n",
        "# Fit the first model\n",
        "random_forest_first_5min.fit(x_train_transformed_first_5min, y_train_first_5min.values.reshape(-1))\n",
        "random_forest_second_5min.fit(x_train_transformed_second_5min, y_train_second_5min.values.reshape(-1))\n",
        "\n",
        "# Custom predict method to use different models based on the 'far_price' condition\n",
        "def custom_predict(x_test):\n",
        "    # Select the rows where 'far_price' is not NaN\n",
        "    x_test_first_5min = x_test[x_test['far_price'].notna()]\n",
        "    x_test_second_5min = x_test[x_test['far_price'].isna()]\n",
        "\n",
        "    # Make predictions with the corresponding model\n",
        "    y_pred_first_5min = random_forest_first_5min.predict(x_test_first_5min)\n",
        "    y_pred_second_5min = random_forest_second_5min.predict(x_test_second_5min)\n",
        "\n",
        "    # Create a combined prediction array\n",
        "    y_pred = pd.Series(index=x_test.index)  # Initialize with NaNs\n",
        "\n",
        "    # Assign predictions to the correct rows\n",
        "    y_pred.loc[x_test_first_5min.index] = y_pred_first_5min\n",
        "    y_pred.loc[x_test_second_5min.index] = y_pred_second_5min\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "y_pred = custom_predict(x_test_transformed)\n",
        "print(f\"Random Forest MAE: {mean_absolute_error(y_test, y_pred)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
